<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Four Tips You Should Know When Writing A Stan Programme</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/blog_menu.jpg" alt="menu pic" /></a>
					<h1><strong><a href="index.html">Home</a></strong><br /></h1>
					<h1><strong><a href="blog.html">[ Blog ]</a></strong><br /></h1>
					<h1><strong><a href="talk.html">Talk</a></strong><br /></h1>
					<h1><strong><a href="research.html">Research</a></strong><br /></h1>
					<h1><strong><a href="personal_record.html">Personal Record</a></strong><br /></h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- Stan debug tips -->
				
					<section id="top">
						<h2>Four Tips You Should Know When Writing A Stan Programme</h2>
						<p><i>July 3, 2023</i></p>
						<p>Estimating parameters of a model is always a thrilling moment, especially when that is your own model! One popular 
							procedure for realizing this goal is the Markov chain Monte Carlo (MCMC) method. It has a long tradition of success in constructing 
							desired posterior distributions and facilitating solutions. For MCMCers, Stan offers a really fast sampler 
							and an easy-to-learn modeling language. With its spectacular features, it has amassed a considerable user base. 
							Although most of our interactions with Stan are joyful, there are still potential holes 
							that might trouble us for several weeks or even months. In this article, I will share four tips to help you avoid pitfalls and 
							save your valuable time!</p>

						<p>Generally, the essential purpose of the this article is to provide you with the optimal workflow I found for writing Stan after 
							lessons paid for with nearly despair and countless hours. I will introduce you two must be done things <strong>*before*</strong> officially 
							starting to write your .stan file. Next, I will highlight a point that commonly being ignored by many people <strong>*during*</strong> the 
							estimation process and equip you with knowledge to diagnose possible problems. Following, I will give you a strategy to fasten your codes.
						</p>

						<section>
							<li>Tip1: &nbsp; <a href="#tip1">Simulation is important.</a></li>
							<li>Tip2: &nbsp; <a href="#tip2">Scrutinizing your variables.</a></li>
							<li>Tip3: &nbsp; <a href="#tip3">Successful convergence is the basis.</a></li>
							<li>Tip4: &nbsp; <a href="#tip4">Storage worths your attention.</a></li>
						</section>
						<br/>

						<p>With the 4S above, you would be further efficient for obtaining the target distribution. Admittedly, it is impossible to include all 
							information in a short article, so I enclosed a list of awesome <a href="#res">Resources</a> at the end. Now let's start!
						</p>

						<hr />

						<section id = "tip1">
							<h2><li>Tip1: &nbsp; Simulation is important.</li></h2>
		
							<p>During the process of programming, the primary concern should be whether the results generated by the program are the desired 
								parameters. A powerful method to verify whether a program can obtain correct and valid parameters is through a simulation study. 
							    Therefore, it is a great start to generate some data using your model. </p>

							<p>With simulation, you can (1) have in-depth communication with the model you wish to estimate. When generating simulated data, 
								you can clearly understand how each parameter works in your model; (2) ensure that the foundation of the Stan program is solid. 
								By analyzing whether the simulated variables have the features that you assume, you can verify whether you have correctly set the prior 
								distribution and likelihood function; (3) get well-prepared for the validation procedure. After writing an MCMC program, you can easily 
								utilize true values set in the simulation to validate your algorithm.</p>
							
							<p>Here is an example. Let's say I want to write an MCMC program for the deterministic inputs, noisy “and” gate (DINA) model. 
								(This is merely an illustrative example and unfamiliarity with this model will not impede your understanding.) The formula of 
							    DINA is as followed, with 0 &lt g_{j} &lt 1-s_{j} &lt 10 &lt g_{j} &lt 1-s_{j} &lt 1 :</p>
							<p>Pr(Yij=1)=(1−sj)ηijg1−ηijjPr(Y_{ij}=1)=(1-s_{j})^{\eta_{ij}}g_{j}^{1 - \eta_{ij}}</p>
							<p>where ii represents the index of examinees with i=(1,...,N)i = (1, ..., N) and jj represents the index of items with j=(1,...,J)j = (1, ..., J). 
								YijY_{ij} stands for the response of examinee ii on item jj with 1 = correct and 0 = incorrect. 
								 \boldsymbol{s} = (s_1, s_2, ..., s_j, ..., s_J) \boldsymbol{s} = (s_1, s_2, ..., s_j, ..., s_J),  \boldsymbol{g} = (g_1, g_2, ..., g_j, ..., g_J) \boldsymbol{g} = (g_1, g_2, ..., g_j, ..., g_J) and  \boldsymbol{\eta} = (0, 1) \boldsymbol{\eta} = (0, 1). 
								It would be excellent to generate some Y_{ij}Y_{ij} before writing a Stan programme.
							</p>

							<pre><code>
# set variables ---------------------------
# (Please note that for the purpose of clarity, I have simplified the actual data generation process.)
<b>J <- 10</b>
<b>N <- 1000</b>
<b>g <- rep(x = 0.2, times = J)</b>
<b>s <- rep(x = 0.2, times = J)</b>
<b>eta_tem <- mvtnorm::rmvnorm(n = N, mean = rep(0, J), sigma = diag(J))</b>
<b>eta <- 1 * (eta_tem > 0)</b>

# define function -------------------------
<b>response <- function(eta, slip, guess){</b>
  # To generate examinees' response for one item
<b>  nper <- length(eta)</b>
	
  ## generate response for one item
<b>  presp <- sapply(1:nper, function(i) {
    (1 - slip)^eta[i] * guess^(1 - eta[i])
  })
  re <- ifelse(test = presp >= runif(n = nper, min = 0, max = 1),
               yes = 1, no = 0)	
  return(re)
}</b>

# data generation -------------------------
<b>respon <- matrix(data = NA, nrow = N, ncol = J)
for (j in 1:J){
  respon[, j] <- response(eta = eta[, j], slip = s[j], guess = g[j])
}
head(respon)</b>
							</code></pre>

							<p>Ideally, $Y_{ij}$ should be a random variable taking on values of 0 or 1. If the generated data conforms to this feature, congratulations!! 
								Additionally, please save this simulation program as it not only generates data but also provides true values for each parameter. 
								These will be used to validate your Stan program.
							</p>											
											
						</section>
						<hr />

						<section id = "tip2">
							<h2><li>Tip2: &nbsp; Scrutinizing your variables.</li></h2>

							<p>Another way to guarantee we can achieve targeted estimates is to carefully examine every parameter you set or every output 
								after your calculation. Confirming that those variables are indeed what you intend them to be. Since in a Stan file we 
								cannot directly view the variables, <i>the print statement</i> is extremely helpful here.</p>
							
							<p>To demonstrate its usage, I presented here a <a href="nothing_but_debug.zip">nothing_but_debug</a> file containing a Stan file 
								that solely includes variables of interest, as well as an R script used for running Stan.</p>

							<p>In the Stan file, you can just include very simple and few elements in the script as our main purpose is to check the values of 
								some specific variables. In our example, we focus on the $s$ and $g$ parameters.
							</p>

							<pre><code><b>data{
  int&lt;lower = 1&gt; J;
}
								  
parameters{
  real&lt;lower = 0, upper = 1&gt; slip[J];
  real&lt;lower = 0, upper = 1&gt; guess[J];
}
								  
model{</b>
<b>  slip ~ beta(5, 10);</b>       # prior of your parameters
<b>  guess ~ beta(5, 10);</b>
									
<b>  print("slip = ", slip);</b>   # cannot be used in the data and parameter blocks
<b>  print("guess = ", guess);</b>
}</b></code></pre>
						<p>Next, we can execute the .stan file in R. One chain with a very short length is favored, which is 
							fast and can print the results directly to the console.
						</p>

						<pre><code><b>J <- 10
data_input <- list(J = J)</b>
							
# run stan -----------------------------
<b>library(rstan)
							
rstan_options(auto_write = TRUE)
estMCMC <- stan_model(file= 'model.stan')
							
set.seed(13137)
stan_inits <- list(list(guess = rep(0.1, times = J),
                        slip = rep(0.1, times = J)))</b>
							
# MCMC
<b>fitMCMC <- sampling(estMCMC,
                    data = data_input,
                    init = stan_inits,
                    iter = 10,
                    chains = 1)</b></code></pre>

						<p>As mentioned eariler, our parameters should satisfy: $0 &lt g_{j} &lt 1-s_{j} &lt 1$. Clearly, 
							the parameters do not meet the requirements as necessary constraints have not been imposed upon them.
						</p>
						
						</section>
						<hr />

						<section id = "tip3">
							<h2><li>Tip3: &nbsp; Successful convergence is the basis.</li></h2>

							<p>After highlighting the role of simulated data and the print statement, I would like to direct your attention to 
								model convergence. Many individuals are eager to retrieve the posterior mean and perform further analysis 
								once finally get to the end of the sampling process. However, if the model has not converged, the posterior 
								mean is highly unreliable, and results based on it are not warranted. Checking the convergence carefully before 
								moving on can prevent you from wasting several months on untrustworthy results.
							</p>
							<p>Here are two points you don't want to miss:</p>
								<ol>
									<li><strong>Has the posterior parameter space been sufficiently explored?</strong> This question can be answered with 
									the trace plot and the Gelman–Rubin $\hat{R}$. For the trace plot, sometimes we are encouraged to use one chain to diagnose 
									problematic parameters, but it is also necessary for us to run more than three chains to detect potential nonconvergence. 
									There is a chance that two or even three chains just happened to mix well with each other, but the fourth chain ended up 
									in a different region which indicates a nonconvergence. For $\hat{R}$, we aim for all parameters with values less than 1.1. 
									This rule should be satisfied not only for the important variables that we are interested in, but also for less significant parameters, 
									as the exploration of one parameter space can make a great difference to the other.</br>
								    You can draw a trace plot by using <code>mcmc_trace()</code> in the bayesplot package, and applying <code>summary()</code> to your stan 
									object to extract the Gelman–Rubin $\hat{R}$.</li>
									<li><strong>Have we collected enough samples from the targeted distribution?</strong> The effective sample size of estimates 
									is a powerful indicator. The estimates would be ready for advanced analysis if the effective sample size for each of them could 
									account for more than 50% total sample size in each chain. This requirement might be a little bit strong, but you would never expect 
									the effective sample size to be less than 100, especially when the chain length is more than 5,000.</br>
									You can view the effective sample size with the <code>summary()</code> function.
								</li>
								</ol>

							<p>There are various sources that may lead to convergence problems. Two common causes are identifiability and prior distribution. For identifiability, 
								you are encouraged to carefully check your model. If it turns out that part of your parameter displayed an extremely low effective sample size, it 
								might be a signal for nonidentifiability. In terms of the prior setting, always using independent and simple prior is a good standard. If a restricted 
								and dependent distribution is required, as in our example which indicated $0 &lt g_{j} &lt 1-s_{j} &lt 1$, we will need to transform the "complex" 
								prior to a "simple" one for convergence. Here are stan codes for the illustration of the transformation process.
							</p>

							<pre><code><b>data{
  int&lt;lower = 1&gt; J;</b>    // number of items
<b>}

parameters {</b>
  // create a new vector (actually matrix) to store ordered parameters
<b>  row_vector<lower = 0, upper = 1>[2] new_pars[J];
}

transformed parameters {
  real&lt;lower = 0, upper = 1&gt; slip[J];
  real&lt;lower = 0, upper = 1&gt; guess[J];

  for (j in 1:J) {</b>
    // arrange the new parameter in ascending order
    // and assign them to the desired position
<b>    guess[j] = sort_asc(new_pars[j])[1];
    slip[j]  = 1 - sort_asc(new_pars[j])[2];
  }
}

model {
  for (j in 1:J){</b>
    // sample new parameters from a simple prior
<b>    new_pars[j] ~ beta(1, 1);
  }
  ...
}</b></code></pre>							
							
							<p>Some final words for this section: setting different initial values for different chains can be helpful 
								to avoid being stuck in the local optimal solution :)
							</p>
							

						</section>
						<hr />

						<section id = "tip4">
							<h2><li>Tip4: &nbsp; Storage worths your attention.</li></h2>

							<p>Memory issues commonly arise when running a model with multiple parameters or generating posterior 
								predictive samples. Exceeding the memory limit can result in the forced termination of a program. 
								Below are two tricks that can help us out:
							</p>

							<ol>
								<li><strong>Exclude non-interested parameters.</strong> We can eliminate specific parameters with the "pars" and "include" arguments. 
									As in the previous case, we are not interested in the transformed parameter, so we can 
									specify <code>sampling(object, data, pars = "new_pars", include = FALSE)</code>. In this way, samples of "new_pars" will not be stored.
								</li>
								<li><strong>Define a local block.</strong> In some cases, we need to generate posterior predictive samples for the posterior predictive checking. 
									The generated posterior samples may occupy considerable storage space, but in reality, we only need to compute some statistical 
									metrics based on these samples. In such cases, we can store only the statistical metrics and treat the posterior samples as local 
									variables enclosed within <code>{}</code>. This restricts their scope to the local block only, significantly reducing memory consumption.
								</li>
							</ol>

						</section>
						<hr />

						<section id = "res">
							<h2><li>Resources</li></h2>
							<ol>
								<li>Welcome to the big family of Stan: <a href="https://discourse.mc-stan.org/">https://discourse.mc-stan.org/</a></li>
								<li>Here are everything about Stan: <a href="https://mc-stan.org/users/documentation/">https://mc-stan.org/users/documentation/</a></li>
								<li>Excellent Bayesian courses offered by Dr. Ben Lambert: <a href="https://youtube.com/playlist?list=PLwJRxp3blEvZ8AKMXOy0fc0cqT61GsKCG">https://youtube.com/playlist?list=PLwJRxp3blEvZ8AKMXOy0fc0cqT61GsKCG</a></li>
								<li>Perfect guide on errors and warnings: <a href="https://mc-stan.org/misc/warnings.html">https://mc-stan.org/misc/warnings.html</a></li>
							</ol>

						</section>

						<br/>
						<br/>

						<ul class="actions">
							<li><a href="ggplot_Codes.html" class="button">Next &rarr;</a></li>
						</ul>						

					</section>
				

			</div>

		<!-- Footer -->
			<footer id="contact">
				<div class="inner">
					<ul class="icons">
						<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<!-- <li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li> -->
						<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>E-mail: h_yingshi@mail.bnu.edu.cn<br />
							<br />
						&copy; 2022 Yingshi</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
